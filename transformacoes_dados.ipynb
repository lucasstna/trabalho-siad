{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import wget\n",
    "import zipfile\n",
    "from urllib.error import HTTPError\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'dados/'\n",
    "\n",
    "folder_renach = 'renach/'\n",
    "folder_infracoes = 'infracoes/'\n",
    "folder_renaest = 'renaest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(root_folder + folder_renach)\n",
    "os.mkdir(root_folder + folder_renaest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:postgres@localhost:5432/siad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando dados de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pd.date_range(start='01-01-2018', end='31-12-2022'), columns=['data'])\n",
    "\n",
    "data['id'] = data.index + 1\n",
    "data['ano'] = data['data'].dt.year\n",
    "data['mes'] = data['data'].dt.month\n",
    "data['ano_mes'] = data['ano'] * 100 + data['mes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    data.to_sql(name='data', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo dados dos arquivos do RENACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root_folder + folder_renach)\n",
    "\n",
    "for ano in [2018, 2019, 2020, 2021, 2022]:\n",
    "    for mes in range(1, 13):    \n",
    "        \n",
    "        try:\n",
    "            data = f'{ano}_{mes:02d}'\n",
    "            url = f'https://www.gov.br/transportes/pt-br/assuntos/transito/arquivos-senatran/estatisticas/renach/csv/condutores_habilitados_{data}.csv'\n",
    "            \n",
    "            wget.download(url)\n",
    "        except:\n",
    "            data = f'{ano}-{mes:02d}'\n",
    "            url = f'https://www.gov.br/transportes/pt-br/assuntos/transito/arquivos-senatran/estatisticas/renach/csv/condutores_habilitados_{data}.csv'\n",
    "\n",
    "            wget.download(url)\n",
    "\n",
    "os.chdir('../..')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(root_folder + folder_renach):\n",
    "    df = pd.read_csv(root_folder + folder_renach + file, encoding='utf_16', decimal=',', thousands='.')\n",
    "\n",
    "    file = file.replace('-', '_')  \n",
    "    df['ano_mes'] = int(file.split('_')[2] + file.split('_')[3].split('.')[0])\n",
    "    df_result = pd.concat([df_result, df], axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adiquirindo a relação de nome/sigla das UFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://servicodados.ibge.gov.br/api/v1/localidades/estados?orderBy=id').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufs = {}\n",
    "for uf in response: ufs[uf['nome']] = uf['sigla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['uf'] = [ufs[nome_uf] for nome_uf in df_result['UF Habilitação Atual']]\n",
    "df_result['categoria_cnh'] = df_result['Categoria'].str.split('-', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result[['uf', 'Sexo', 'Faixa Etária', 'categoria_cnh', 'Qt. Condutor Histórico', 'ano_mes']]\n",
    "\n",
    "quantidade_condutores = df_result.rename(columns={\n",
    "    'Sexo':'sexo',\n",
    "    'Faixa Etária':'faixa_etaria',\n",
    "    'Qt. Condutor Histórico':'qtd_condutores'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_condutores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    quantidade_condutores.to_sql(name='quantidade_condutores', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiquirindo dados sobre os tipos de infrações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root_folder + folder_infracoes)\n",
    "\n",
    "try:\n",
    "    url = 'https://www.gov.br/transportes/pt-br/centrais-de-conteudo/tabela-codigo-infracoes-renainf-xlsx'\n",
    "    \n",
    "    wget.download(url)\n",
    "except:\n",
    "    print('Erro de download.')\n",
    "\n",
    "os.chdir('../..')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infracoes = pd.read_excel(root_folder + folder_infracoes + 'codigos/tabela-codigo-infracoes-renainf-xlsx.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infracoes['id'] = df_infracoes.index + 1\n",
    "df_infracoes = df_infracoes[['id', 'Código da Infração', 'Descrição da Infração', 'Gravidade', 'Órgão Competente']]\n",
    "\n",
    "infracoes = df_infracoes.rename(columns={\n",
    "    'Código da Infração':'codigo_infracao',\n",
    "    'Descrição da Infração':'descricao_infracao',\n",
    "    'Gravidade':'gravidade',\n",
    "    'Órgão Competente':'orgao_competente'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infracoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    infracoes.to_sql(name='infracoes', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiquirindo dados do RENAEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root_folder + folder_renaest)\n",
    "\n",
    "try:\n",
    "    url = 'http://dados.transportes.gov.br/dataset/42e2320b-ea67-4fdc-896f-71363e043fc6/resource/73b35d71-d701-441c-83da-405c9e7bb145/download/renaest_dabertos_20230412.zip'\n",
    "    \n",
    "    wget.download(url)\n",
    "except:\n",
    "    print('Erro de download.')\n",
    "\n",
    "os.chdir('../..')  \n",
    "\n",
    "# extrai os arquivos\n",
    "with zipfile.ZipFile(root_folder + folder_renaest + 'renaest_dabertos_20230412.zip') as zip_ref:\n",
    "    zip_ref.extractall(root_folder + folder_renaest)\n",
    "\n",
    "os.remove(root_folder + folder_renaest + 'renaest_dabertos_20230412.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidade = pd.read_csv('dados/renaest/Localidade_DadosAbertos_20230412.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidade.drop_duplicates(subset=['mes_ano_referencia', 'codigo_ibge'], inplace=True)\n",
    "df_localidade = df_localidade[df_localidade['ano_referencia'] < 2023]\n",
    "\n",
    "df_localidade['ano_mes'] = df_localidade['ano_referencia'] * 100 + df_localidade['mes_referencia']\n",
    "df_localidade['metropolitana'] = df_localidade['regiao_metropolitana'] == 'sim'\n",
    "\n",
    "df_localidade = df_localidade.rename(columns={\n",
    "    'qtde_habitantes':'qtd_habitantes'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidade = df_localidade[['ano_mes', 'municipio', 'uf', 'metropolitana', 'qtd_habitantes', 'frota_total', 'frota_circulante', 'regiao', 'codigo_ibge']].reset_index(drop=True)\n",
    "localidade['id'] = localidade.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    localidade.to_sql(name='localidade', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veiculo = pd.read_csv('dados/renaest/TipoVeiculo_DadosAbertos_20230412.csv', sep=';')\n",
    "\n",
    "veiculo = df_veiculo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veiculo.drop_duplicates(subset=['tipo_veiculo'], inplace=True)\n",
    "veiculo = veiculo[['tipo_veiculo']].reset_index(drop=True)\n",
    "veiculo['id'] = veiculo.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veiculo = veiculo.rename(columns={\n",
    "    'tipo_veiculo':'tipo'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veiculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    veiculo.to_sql(name='veiculo', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vítimas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vitimas = pd.read_csv('dados/renaest/Vitimas_DadosAbertos_20230412.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vitimas = df_vitimas[['num_acidente', 'faixa_idade', 'genero', 'tp_envolvido', 'susp_alcool']].reset_index(drop=True)\n",
    "df_vitimas['id'] = df_vitimas.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitimas = df_vitimas.rename(columns={\n",
    "    'tp_envolvido':'tipo',\n",
    "    'susp_alcool':'suspeita_alcoolizado'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    vitimas.to_sql(name='vitimas', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = pd.read_csv('dados/renaest/Acidentes_DadosAbertos_20230412.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes['ano_mes'] = df_acidentes['ano_acidente'] * 100 + df_acidentes['mes_acidente']\n",
    "df_acidentes['data_acidente'] = pd.to_datetime(df_acidentes['data_acidente'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes.merge(\n",
    "    localidade,\n",
    "    how='inner',\n",
    "    on=['codigo_ibge', 'ano_mes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes.rename(columns={'id':'id_localidade'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes.merge(\n",
    "    vitimas,\n",
    "    how='inner', \n",
    "    on=['num_acidente']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes.rename(columns={'id':'id_vitima'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes[['num_acidente', 'id_localidade', 'id_vitima', 'data_acidente', 'tp_acidente', 'cond_meteorologica', 'qtde_envolvidos', 'qtde_feridosilesos', 'qtde_obitos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes.merge(\n",
    "    df_veiculo,\n",
    "    how='inner',\n",
    "    on=['num_acidente']\n",
    ").merge(\n",
    "    veiculo,\n",
    "    how='inner',\n",
    "    left_on=['tipo_veiculo'],\n",
    "    right_on=['tipo']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes[['num_acidente', 'id_localidade', 'id', 'id_vitima', 'data_acidente', 'tp_acidente', 'cond_meteorologica', 'qtde_envolvidos', 'qtde_feridosilesos', 'qtde_obitos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes.merge(\n",
    "    data,\n",
    "    how='inner',\n",
    "    left_on=['data_acidente'],\n",
    "    right_on=['data']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes = df_acidentes[['num_acidente', 'id_localidade', 'id_x', 'id_vitima', 'id_y', 'data_acidente', 'tp_acidente', 'cond_meteorologica', 'qtde_envolvidos', 'qtde_feridosilesos', 'qtde_obitos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acidentes = df_acidentes.rename(columns={\n",
    "    'id_x':'id_veiculo',\n",
    "    'id_y':'id_data',\n",
    "    'tp_acidente':'tipo_acidente',\n",
    "    'qtde_feridosilesos':'qtde_feridos_ilesos'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    acidentes.to_sql(name='acidentes', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiquirindo os dados de quantidades de infrações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root_folder + folder_infracoes)\n",
    "\n",
    "for ano in [2019, 2020, 2021, 2022]:    \n",
    "    for mes in range(1, 13):    \n",
    "        \n",
    "        try:\n",
    "            data = f'{ano}_{mes:02d}'\n",
    "            url = f'https://www.gov.br/transportes/pt-br/assuntos/transito/arquivos-senatran/estatisticas/renainf/xlsx/{data}_infracoes_com_np.xlsx'\n",
    "            \n",
    "            wget.download(url)\n",
    "        \n",
    "        except HTTPError as error:\n",
    "            \n",
    "            try:\n",
    "                data = f'{ano}-{mes:02d}'\n",
    "                url = f'https://www.gov.br/transportes/pt-br/assuntos/transito/arquivos-senatran/estatisticas/renainf/xlsx/{data}_infracoes_com_np.xlsx'\n",
    "\n",
    "                wget.download(url)\n",
    "            except:\n",
    "                print(error)\n",
    "                print(f'{data} não presente.')\n",
    "                pass\n",
    "\n",
    "os.chdir('../..')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_cabecalho_tipo_1(path):    \n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "\n",
    "    file = path.split('/')[-1]\n",
    "    df.columns = df.iloc[2]\n",
    "    df = df.iloc[4:-1]\n",
    "\n",
    "    # recupera o ano_mes que está sendo analisado\n",
    "    file = file.replace('-', '_')  \n",
    "    ano_mes = int(file.split('_')[0] + file.split('_')[1]) \n",
    "\n",
    "    # coloca o df no formato desejado para obter os dados\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.columns.values[0] = 'codigo_infracao'\n",
    "        \n",
    "    df.set_index('codigo_infracao', inplace=True)\n",
    "\n",
    "    return df, ano_mes\n",
    "\n",
    "def processa_cabecalho_tipo_2(path):\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "\n",
    "    file = path.split('/')[-1]\n",
    "    \n",
    "    # recupera o ano_mes que está sendo analisado\n",
    "    file = file.replace('-', '_')  \n",
    "    ano_mes = int(file.split('_')[0] + file.split('_')[1]) \n",
    "    \n",
    "    df.columns = df.iloc[4]\n",
    "    # trata última linha do arquivo que é usada como totalizador\n",
    "    if ano_mes <= 202009:\n",
    "        df = df.iloc[6:-1]\n",
    "    else:\n",
    "        df = df.iloc[6:]\n",
    "\n",
    "    # coloca o df no formato desejado para obter os dados\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.columns.values[0] = 'codigo_infracao'\n",
    "        \n",
    "    df.set_index('codigo_infracao', inplace=True)\n",
    "\n",
    "    return df, ano_mes\n",
    "\n",
    "def processa_cabecalho_tipo_3(path):\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "\n",
    "    file = path.split('/')[-1]\n",
    "\n",
    "    # recupera o ano_mes que está sendo analisado\n",
    "    file = file.replace('-', '_')  \n",
    "    ano_mes = int(file.split('_')[0] + file.split('_')[1]) \n",
    "\n",
    "    df.rename(columns={\n",
    "        'UF':'uf',\n",
    "        'Codigo_Infracao':'codigo_infracao',\n",
    "        'Cod_Infracao':'codigo_infracao',\n",
    "        'Quantidade':'qtd'\n",
    "    }, inplace=True)\n",
    "        \n",
    "    df['ano_mes'] = ano_mes\n",
    "\n",
    "    return df\n",
    "\n",
    "def processa_cabecalho_tipo_4(path):\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "\n",
    "    file = path.split('/')[-1]\n",
    "\n",
    "    df = df[1:]\n",
    "\n",
    "    # recupera o ano_mes que está sendo analisado\n",
    "    file = file.replace('-', '_')  \n",
    "    ano_mes = int(file.split('_')[0] + file.split('_')[1]) \n",
    "\n",
    "    # coloca o df no formato desejado para obter os dados\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.columns.values[0] = 'codigo_infracao'\n",
    "        \n",
    "    df.set_index('codigo_infracao', inplace=True)\n",
    "\n",
    "    return df, ano_mes\n",
    "\n",
    "def processa_cabecalho_tipo_5(path):\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "\n",
    "    file = path.split('/')[-1]\n",
    "\n",
    "    df = df[1:]\n",
    "\n",
    "    # recupera o ano_mes que está sendo analisado\n",
    "    file = file.replace('-', '_')  \n",
    "    ano_mes = int(file.split('_')[0] + file.split('_')[1]) \n",
    "\n",
    "    # coloca o df no formato desejado para obter os dados\n",
    "    df.columns.values[0] = 'codigo_infracao'\n",
    "        \n",
    "    df.set_index('codigo_infracao', inplace=True)\n",
    "\n",
    "    return df, ano_mes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formata_df(df, ano_mes):\n",
    "    # para cada arquivo, adiciona ano_mes e modifica o formato do df\n",
    "    df_temp = pd.DataFrame()\n",
    "\n",
    "    for idx in range(len(df.index)): #27 estados\n",
    "\n",
    "        df2 = pd.DataFrame(data={\n",
    "            'uf':df.columns,\n",
    "            'qtd':df.iloc[idx].tolist(),\n",
    "            'codigo_infracao':df.iloc[idx].name,\n",
    "            'ano_mes':ano_mes\n",
    "        })\n",
    "\n",
    "        df_temp = pd.concat([df_temp, df2], axis='index')\n",
    "\n",
    "    # guarda os valores no df final\n",
    "    df_temp.dropna(subset=['qtd'], inplace=True)\n",
    "\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "folder_path = root_folder + folder_infracoes + 'cabecalho_1/'\n",
    "for file in os.listdir(folder_path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df, ano_mes = processa_cabecalho_tipo_1(folder_path + file)\n",
    "    df_temp = pd.concat([df_temp, formata_df(df, ano_mes)], axis='index')\n",
    "\n",
    "df_result = pd.concat([df_result, df_temp], axis='index')\n",
    "\n",
    "folder_path = root_folder + folder_infracoes + 'cabecalho_2/'\n",
    "for file in os.listdir(folder_path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df, ano_mes = processa_cabecalho_tipo_2(folder_path + file)\n",
    "    df_temp = pd.concat([df_temp, formata_df(df, ano_mes)], axis='index')\n",
    "\n",
    "df_result = pd.concat([df_result, df_temp], axis='index')\n",
    "\n",
    "folder_path = root_folder + folder_infracoes + 'cabecalho_3/'\n",
    "for file in os.listdir(folder_path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df = processa_cabecalho_tipo_3(folder_path + file)\n",
    "    df_temp = pd.concat([df_temp, df], axis='index')\n",
    "\n",
    "df_result = pd.concat([df_result, df_temp], axis='index')\n",
    "\n",
    "folder_path = root_folder + folder_infracoes + 'cabecalho_4/'\n",
    "for file in os.listdir(folder_path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df, ano_mes = processa_cabecalho_tipo_4(folder_path + file)\n",
    "    df_temp = pd.concat([df_temp, formata_df(df, ano_mes)], axis='index')\n",
    "\n",
    "df_result = pd.concat([df_result, df_temp], axis='index')\n",
    "\n",
    "folder_path = root_folder + folder_infracoes + 'cabecalho_5/'\n",
    "for file in os.listdir(folder_path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df, ano_mes = processa_cabecalho_tipo_5(folder_path + file)\n",
    "    df_temp = pd.concat([df_temp, formata_df(df, ano_mes)], axis='index')\n",
    "\n",
    "df_result = pd.concat([df_result, df_temp], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_infracoes = df_result.merge(\n",
    "    infracoes,\n",
    "    how='left',\n",
    "    on='codigo_infracao'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_infracoes.rename(columns={\n",
    "    'id':'id_infracao'\n",
    "}, inplace=True)\n",
    "\n",
    "quantidade_infracoes = quantidade_infracoes[['id_infracao', 'ano_mes', 'uf', 'qtd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_infracoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    quantidade_infracoes.to_sql(name='quantidade_infracoes', con=conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
